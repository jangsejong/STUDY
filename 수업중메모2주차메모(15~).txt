11/29
선형회귀법(Linear Regression) : 
단순 선형 회귀 _ simple linear regression
다중 선형 회귀 _ multiple linear regression

시그모이드함수 (sigmoid) : logit과 sigmoid는 역함수 관계
                        2개의 클래스로 정의하던 logit을 K 개의 클래스로 확장하면 softmax
                        Sigmoid를 K 개 클래스를 대상으로 일반화하면 softmax, softmax에서 K=2로 두면 sigmoid로 환원
                        소프트맥스와 시그모이드의 가장 큰 차이는 값 개수이다.
                        소프트맥스는 다분류 출력이 가능하다
                        그러나 시그모이드는 이진분류의 경우 사용하며 실수 값 기준으로 (0.5이상 or not) 0이나 1로 출력한다
                        링크 : https://blog.naver.com/th9231/221989350922
                        그리고 용도가 소프트맥스는 보통 출력층(classification)에 사용하고
                        시그모이드는 중간에 activation function으로 사용된다.
이진분류의 activation = Sigmoid
                Loss = Binary Cross Entropy                       

부동소수점연산 : 부동 소수점 수 사이에서 일어나는 사칙 연산
                floating point operation의 약어. 
                매우 큰 수 또는 작은 수를 나타내거나 그러한 수를 높은 정밀도로 취급하기 위해 부동 소수점 수를 이용한 연산. 
                소수점의 위치를 컴퓨터 내부에서 자동적으로 조정하게 되므로, 프로그램에서는 소수점의 위치를 맞출 필요가 없다는 장점이 있어 복잡한 과학 기술 계산에 많이 사용된다.

디폴트 (default) : 응용 프로그램에서 사용자가 별도의 명령을 내리지 않았을 때, 시스템이 미리 정해진 값이나 조건을 자동으로 적용시키는 것. 
                운영 체계(OS)의 명령어들은 대부분 많은 종류의 매개 변수나 선택 사항을 지정해야 하는데, 
                이러한 매개 변수나 선택 사항을 사용자가 생략하면 시스템이 가장 자주 쓰이는 것으로 설정하거나 명령어의 의미로부터 적절한 값을 선택하는 경우가 많다. 
                워드 프로세서에서 별도로 지정하지 않는 한 종이의 여백이 미리 정해진 규격으로 설정되는 것 등이 그 예이다.

binary crossentropy :
만약 이진 분류기를 훈련하려면, binary crossentropy 손실함수를 사용하면 됩니다. 
이진 분류기라는 것은 True 또는 False, 양성 또는 음성 등 2개의 클래스를 분류할 수 있는 분류기를 의미합니다. 

loss = cost = 손실 = 평가지표
==================================
1. categorical_crossentropy
다중 분류 손실 함수
출력 값이 one-hot encoding된 결과로 나온다. -> label(y)을 one-hot encoding해서 넣어줘야 함
클래스가 상호 배타적일 경우(e.g. 각 샘플이 정확히 하나의 클래스에 속하는 경우) 사용
 

2. sparse_categorical_crossentropy
다중 분류 손실 함수
integer type 클래스 -> one-hot encoding하지 않고 정수 형태로 label(y)을 넣어줌
한 샘플에 여러 클래스가 있거나 label이 soft 확률일 경우 사용
 

3. binary_crossentropy
binary 다중 분류 손실 함수
label들이 독립적일 때 사용
-----------
원-핫 인코딩 (One-Hot Encoding)
관련 링크 : https://wikidocs.net/22647

12/01
# 데이터 스케일링 (Data scaling)
minmax scaler : x값을 0~1 사이로 변환
과적합을 해결하기 위해서  train 비율 만큼 test 도 변환하여 predict 과적합을 방지한다
link : https://homeproject.tistory.com/3


